{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GadKnrqZddyt"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AlexeyAB/darknet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOnRfzg1bmUU"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary library 'drive' from the package 'google.colab'\n",
        "from google.colab import drive\n",
        "\n",
        "# Mounting the Google Drive to the Colab runtime\n",
        "# This allows access to files and directories in the Google Drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiKODHKc9nrO"
      },
      "outputs": [],
      "source": [
        "#This line of code installs the FiftyOne library using pip.\n",
        "#FiftyOne is a Python package that provides interactive exploration, analysis, and visualization of datasets for computer vision tasks.\n",
        "!pip install fiftyone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWU0HyRztK97"
      },
      "outputs": [],
      "source": [
        "import random  # Importing the random module for generating random numbers\n",
        "import fiftyone as fo  # Importing the fiftyone library for working with datasets and models\n",
        "import fiftyone.zoo as foz  # Importing the fiftyone.zoo module for accessing pre-trained models\n",
        "from fiftyone import ViewField as F  # Importing the ViewField class from the fiftyone module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ5zpUS6Uo-v"
      },
      "outputs": [],
      "source": [
        "# Define a list of COCO classes for object relabeling\n",
        "'''\n",
        "relabeling_classes = [\n",
        "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\",\n",
        "    \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\",\n",
        "    \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\",\n",
        "    \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
        "    \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
        "    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
        "    \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\",\n",
        "    \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\",\n",
        "    \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\",\n",
        "    \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\",\n",
        "    \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
        "    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\",\n",
        "    \"hair drier\", \"toothbrush\"\n",
        "]\n",
        "relabeling_classes = [\n",
        "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\",\n",
        "    \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\"\n",
        "]\n",
        "\n",
        "labeling_classes = [\n",
        "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\",\n",
        "    \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\"\n",
        "]\n",
        "'''\n",
        "#shrink relabeling classes to 3 for faster training.\n",
        "relabeling_classes = [\n",
        "    \"cat\", \"dog\", \"horse\"\n",
        "]\n",
        "\n",
        "# this is used to export the class list to the converted yolov4 format data.\n",
        "\n",
        "labeling_classes = [\n",
        "    \"cat\", \"dog\", \"horse\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JvZgJxcukt1"
      },
      "outputs": [],
      "source": [
        "def dwonload_dataset(class_name, max_samples):\n",
        "\n",
        "  dataset = foz.load_zoo_dataset( # Load a dataset from the zoo using foz.load_zoo_dataset() function\n",
        "      \"coco-2017\",\n",
        "      splits=[\"train\"],\n",
        "      classes= class_name,        # Specify the name of the dataset as \"coco-2017\"\n",
        "      max_samples= max_samples   # Specify the maximum number of samples to load from the dataset based on the provided max_samples argument\n",
        "  )\n",
        "  dataset.persistent = True       # Set the persistent attribute of the dataset to True, indicating that it should be saved and loaded from disk if necessary\n",
        "\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8ehUjqaotk4"
      },
      "outputs": [],
      "source": [
        "def clone_and_split_test(dataset, class_name):\n",
        "\n",
        "  class_dataset = dataset.clone()  # Clone the original dataset\n",
        "  class_dataset.persistent = True  # Set the persistent flag to True, indicating that the cloned dataset should persist in memory\n",
        "\n",
        "  class_test_dataset = dataset.clone()  # Clone the original dataset\n",
        "  class_test_dataset.persistent = True  # Set the persistent flag to True, indicating that the cloned dataset should persist in memory\n",
        "\n",
        "  class_dataset_view = class_dataset.filter_labels(\"ground_truth\", F(\"label\").is_in([class_name])).limit(1000)  # Create a view of the class_dataset, filtered by the given class_name and limited to 1000 samples\n",
        "\n",
        "  class_test_view = class_test_dataset.filter_labels(\"ground_truth\", F(\"label\").is_in([class_name])).skip(1000)  # Create a view of the class_test_dataset, filtered by the given class_name and skipping the first 1000 samples\n",
        "\n",
        "  return class_dataset_view.clone(), class_test_view.clone()  # Return the cloned views of the class_dataset and class_test_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFpvwFGgz1AX"
      },
      "outputs": [],
      "source": [
        "def merge_dataset(dataset, class_name):\n",
        "\n",
        "  temp1 = dataset.clone()  # Create a clone of the dataset and store it in 'temp1' variable\n",
        "  temp = temp1.filter_labels(\"ground_truth\", F(\"label\").is_in([\"cat\"]))  # Filter the dataset to include only samples with the label \"cat\" in the \"ground_truth\" field, and store the result in 'temp' variable\n",
        "\n",
        "  for sample in temp.select_fields('tags').iter_samples(autosave=True):  # Iterate over each sample in 'temp' dataset, selecting only the 'tags' field, and enabling autosave\n",
        "    sample.set_field('tags', ['train'])  # Set the 'tags' field of the current sample to ['train']\n",
        "\n",
        "  temp.keep()  # Remove any intermediate data and keep only the modified dataset 'temp'\n",
        "\n",
        "  return temp.clone()  # Return a clone of the modified dataset 'temp'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UccCTalEzSSK"
      },
      "outputs": [],
      "source": [
        "def resize_dataset(dataset, percentage):\n",
        "\n",
        "  print(len(dataset))  # Print the length of the dataset to check its initial size\n",
        "  temp = dataset.take(int(len(dataset) * percentage/100))  # Take a portion of the dataset based on the given percentage\n",
        "\n",
        "  return temp.clone()  # Return a copy of the extracted portion of the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upUTVkZczeAI"
      },
      "outputs": [],
      "source": [
        "def resplit(dataset, percentage):\n",
        "\n",
        "  total_len = len(dataset)  # Calculate the total length of the dataset\n",
        "  train_len = int(total_len * percentage / 100)  # Calculate the length of the training set based on the percentage\n",
        "  val_len = total_len - train_len  # Calculate the length of the validation set by subtracting the training set length from the total length\n",
        "\n",
        "  print('train:', train_len, ' validiation:', val_len, ' total:', total_len)  # Print the lengths of the training set, validation set, and total dataset\n",
        "\n",
        "  train_set = dataset.limit(train_len)  # Limit the dataset to the length of the training set to create the training set\n",
        "  val_set = dataset.skip(train_len).limit(val_len)  # Skip the training set length and limit the dataset to the length of the validation set to create the validation set\n",
        "\n",
        "\n",
        "  for sample in train_set.select_fields('tags').iter_samples(autosave=True):\n",
        "    sample.set_field('tags', ['train'])  # Set the 'tags' field of each sample in the training set to ['train']\n",
        "\n",
        "  for sample in val_set.select_fields('tags').iter_samples(autosave=True):\n",
        "    sample.set_field('tags', ['validation'])  # Set the 'tags' field of each sample in the validation set to ['validation']\n",
        "\n",
        "  return train_set.clone(), val_set.clone()  # Return the cloned versions of the training set and validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHW0zUW-0kAN"
      },
      "outputs": [],
      "source": [
        "def add_label_error(dataset, percentage, class_name):\n",
        "\n",
        "  total_len = len(dataset)\n",
        "  label_error_len = int(total_len * percentage / 100)\n",
        "  error_free_len = total_len - label_error_len\n",
        "\n",
        "  # randomly split the dataset into error and error free sets using the given ratio\n",
        "  label_error_set = dataset.limit(label_error_len)\n",
        "  error_free_set = dataset.skip(label_error_len).limit(error_free_len)\n",
        "\n",
        "  # Check if there are three relabeling classes and remove the specified class\n",
        "  if (len(relabeling_classes)==3):\n",
        "    relabeling_classes.remove(class_name)\n",
        "\n",
        "  # Iterate over each sample in the label error set\n",
        "  for sample in label_error_set.iter_samples(autosave=True):\n",
        "\n",
        "    # Iterate over each detection in the sample's ground truth\n",
        "    for detection in sample.ground_truth.detections:\n",
        "      # Generate a new label randomly from the relabeling classes\n",
        "      new_label = random.choice(relabeling_classes)\n",
        "      # Check if the detection label is the specified class\n",
        "      if detection.label == class_name:\n",
        "        # Assign the new label to the detection\n",
        "        detection.label = new_label\n",
        "        # Print the new label\n",
        "        print(new_label)\n",
        "\n",
        "    # Save the modified sample\n",
        "    sample.save()\n",
        "\n",
        "  # Save the label error set\n",
        "  label_error_set.save()\n",
        "\n",
        "  # Print the number of images with label errors\n",
        "  print(\"number of images with label errors = \", len(label_error_set))\n",
        "\n",
        "  # Concatenate the label error set and error-free set\n",
        "  concat_data_set = label_error_set.concat(error_free_set)\n",
        "  # Shuffle the concatenated dataset\n",
        "  shuffled_data = concat_data_set.shuffle()\n",
        "\n",
        "  # Check if there are two relabeling classes and insert the specified class at the beginning\n",
        "  if (len(relabeling_classes)==2):\n",
        "    relabeling_classes.insert(0, class_name)\n",
        "\n",
        "  # Return a clone of the shuffled dataset\n",
        "  return shuffled_data.clone()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiDizbNc_vHG"
      },
      "outputs": [],
      "source": [
        "def generateDataset(dataset, class_name, size, resplit_percent):\n",
        "  train_dataset, test_dataset = clone_and_split_test(dataset, class_name)\n",
        "  #merged_dataset = merge_dataset(train_dataset, class_name)\n",
        "  resized_dataset = resize_dataset(train_dataset, size)\n",
        "  label_error_dataset = add_label_error(resized_dataset, error_rate, class_name)\n",
        "  train_set, val_set = resplit(label_error_dataset, resplit_percent)\n",
        "\n",
        "\n",
        "  return train_set, val_set, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn_2UPCSCx61"
      },
      "outputs": [],
      "source": [
        "class_name = 'cat'\n",
        "max_samples = 4000\n",
        "dataset = dwonload_dataset(class_name, max_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prepare test and valiation data"
      ],
      "metadata": {
        "id": "jvepI-5VKYR3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lam-c1JYU24r"
      },
      "outputs": [],
      "source": [
        "exp_name = \"E2D30\"\n",
        "\n",
        "size = 30                               # will shrink the size by a percentage if 90 then the new size will be 90% of the orginal\n",
        "resplit_precent = 80                    # will assign the training set using the precentage given.\n",
        "error_rate = 0                          # will add error rate according to the precentage given.\n",
        "\n",
        "\n",
        "train_data, val_data, test_data = generateDataset(dataset, class_name, size, resplit_precent)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceJGJk1VXf9c"
      },
      "outputs": [],
      "source": [
        "#session = fo.launch_app(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sf2Qmr7hVHn"
      },
      "outputs": [],
      "source": [
        "print(\"length of training set = \",len(train_data))\n",
        "print(\"length of validation set = \",len(val_data))\n",
        "print(\"length of test set = \",len(test_data))\n",
        "print(\"********************************************\")\n",
        "i = 0\n",
        "for sample in val_data:\n",
        "  i += 1\n",
        "  #print(i , '- ', sample.ground_truth.detections, ' - ', sample.tags)\n",
        "  print(i , '- ', sample.ground_truth.detections[0].label, ' - ', sample.tags)\n",
        "print(\"********************************************\")\n",
        "print(\"length of training set = \",len(train_data))\n",
        "print(\"length of validation set = \",len(val_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NJe7mO9xHft"
      },
      "outputs": [],
      "source": [
        "#!rm -rf /content/darknet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAqhBaK67JyY"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/AlexeyAB/darknet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npXJWJQJ7Py-"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0diwDt_gxIIM"
      },
      "outputs": [],
      "source": [
        "%cd /content/darknet\n",
        "%rm -rf data/\n",
        "%mkdir data/\n",
        "%cd data\n",
        "%mkdir labels/\n",
        "%cd /content/darknet\n",
        "%rm -rf cfg/\n",
        "%mkdir cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqRdpxrCjGhD"
      },
      "outputs": [],
      "source": [
        "export_dir = \"/content/darknet/data\"\n",
        "data_path = \"/content/darknet/data/obj\"\n",
        "labels_path = \"/content/darknet/data/obj\"\n",
        "images_path = \"/content/darknet/train.txt\"\n",
        "label_field = \"ground_truth\"  # for example\n",
        "\n",
        "# The dataset or view to export\n",
        "dataset_or_view = train_data\n",
        "\n",
        "# Export the dataset\n",
        "dataset_or_view.export(\n",
        "    export_dir=export_dir,\n",
        "    dataset_type=fo.types.YOLOv4Dataset,\n",
        "    label_field=label_field,\n",
        "    classes= labeling_classes,\n",
        "    data_path = data_path,\n",
        "    labels_path = labels_path,\n",
        "    images_path = images_path,\n",
        ")\n",
        "%cd /content/darknet\n",
        "!mv train.txt data/train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvFe24xtnvX_"
      },
      "outputs": [],
      "source": [
        "export_dir = \"/content/darknet/data\"\n",
        "data_path = \"/content/darknet/data/obj\"\n",
        "labels_path = \"/content/darknet/data/obj\"\n",
        "images_path = \"/content/darknet/val.txt\"\n",
        "label_field = \"ground_truth\"  # for example\n",
        "\n",
        "# The dataset or view to export\n",
        "dataset_or_view = val_data\n",
        "\n",
        "# Export the dataset\n",
        "dataset_or_view.export(\n",
        "    export_dir=export_dir,\n",
        "    dataset_type=fo.types.YOLOv4Dataset,\n",
        "    label_field=label_field,\n",
        "    classes= labeling_classes,\n",
        "    data_path = data_path,\n",
        "    labels_path = labels_path,\n",
        "    images_path = images_path,\n",
        ")\n",
        "%cd /content/darknet\n",
        "!mv val.txt data/val.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ha3hD6IiL-z"
      },
      "outputs": [],
      "source": [
        "!cp /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/config/obj.data /content/darknet/data\n",
        "#!cp /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/config/obj.names /content/darknet/build/darknet/x64/data\n",
        "!cp -r /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/config/cfg /content/darknet/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbmQA9HhnbQt"
      },
      "outputs": [],
      "source": [
        "# will show the folder size\n",
        "!du -sh /content/darknet/data\n",
        "!du -sh /content/data/{exp_name}\n",
        "!du -sh /content/terminal/{exp_name}.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data/"
      ],
      "metadata": {
        "id": "8KvSXgNcqkyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRaldzsVpzSl"
      },
      "outputs": [],
      "source": [
        "#%cd data/\n",
        "!sed -i 's@^backup = /mimer/NOBACKUP/groups/naiss2023-22-457/.*@backup = /mimer/NOBACKUP/groups/naiss2023-22-457/Experiments_results/{exp_name}/weights@' obj.data\n",
        "#!sed -i 's@classes = @classes = 3@' obj.data\n",
        "!sed -i 's/^classes = .*/classes = 3/' obj.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io8zbrO9rySu"
      },
      "outputs": [],
      "source": [
        "!cat /content/darknet/data/obj.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBIdS9W5swSd"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/terminal\n",
        "!mkdir -p /content/data/{exp_name}/data\n",
        "!mkdir -p /content/data/{exp_name}/cfg\n",
        "!mkdir -p /content/data/{exp_name}/weights\n",
        "!cp -r /content/darknet/data /content/data/{exp_name}\n",
        "!cp -r /content/darknet/cfg /content/data/{exp_name}\n",
        "#!mv /content/data/{exp_name}.zip /content/terminal/{exp_name}\n",
        "#!cp -r /content/terminal/{exp_name}.zip /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "%cd /content/data/\n",
        "!zip -r /content/terminal/{exp_name}.zip ./{exp_name}/*\n",
        "%cd /content/darknet/data"
      ],
      "metadata": {
        "id": "hP4Jk4pfCNqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36GBepBf6BEi"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/terminal/{exp_name}.zip /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!zip -r /content/terminal/{exp_name}.zip /content/data/{exp_name}/*"
      ],
      "metadata": {
        "id": "LlW9wVs3CDqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3f-xvIh9YUI"
      },
      "outputs": [],
      "source": [
        "#!rm -rf /content/data/{exp_name}\n",
        "#!rm -rf /content/terminal/{exp_name}.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PREPARE TEST DATA\n",
        "the test data is made of one class \"cat\" an consist of 3000 images."
      ],
      "metadata": {
        "id": "uJ0LxlDMvBvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/darknet/testData\n",
        "!rm -rf /content/darknet/cfg\n",
        "!rm -rf /content/data/testData\n",
        "!rm -rf /content/terminal/testData.zip\n",
        "!mkdir -p /content/darknet/testData/labels/\n",
        "!mkdir -p /content/darknet/cfg"
      ],
      "metadata": {
        "id": "gywnmFTuvnxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "id": "yphrroPbZj-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlXHYCh3n_XC"
      },
      "outputs": [],
      "source": [
        "\n",
        "export_dir = \"/content/darknet/testData\"\n",
        "data_path = \"/content/darknet/testData/obj\"\n",
        "labels_path = \"/content/darknet/testData/obj\"\n",
        "images_path = \"/content/darknet/test.txt\"\n",
        "label_field = \"ground_truth\"  # for example\n",
        "\n",
        "# The dataset or view to export\n",
        "dataset_or_view = test_data\n",
        "\n",
        "# Export the dataset\n",
        "dataset_or_view.export(\n",
        "    export_dir=export_dir,\n",
        "    dataset_type=fo.types.YOLOv4Dataset,\n",
        "    label_field=label_field,\n",
        "    classes= labeling_classes,\n",
        "    data_path = data_path,\n",
        "    labels_path = labels_path,\n",
        "    images_path = images_path,\n",
        ")\n",
        "\n",
        "!mv /content/darknet/test.txt /content/darknet/testData/test.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kC_c5teaw8Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrXU04AJw9Ye"
      },
      "outputs": [],
      "source": [
        "!cp /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/config/obj.data /content/darknet/testData/\n",
        "#!cp /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/config/obj.names /content/darknet/build/darknet/x64/data\n",
        "!cp /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/config/yolo-obj.cfg /content/darknet/cfg\n",
        "!cp /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/config/yolo-obj-test.cfg /content/darknet/cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td2l-Fbww9Ye"
      },
      "outputs": [],
      "source": [
        "# will show the folder size\n",
        "!du -sh /content/darknet/testData\n",
        "!du -sh /content/data/testData\n",
        "!du -sh /content/terminal/testData.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/darknet/testData/"
      ],
      "metadata": {
        "id": "rJAbdp1fw9Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uM3aPghw9Yf"
      },
      "outputs": [],
      "source": [
        "#%cd data/\n",
        "exp_name = \"testData\"\n",
        "!sed -i 's/^classes = .*/classes = 3/' obj.data\n",
        "!sed -i 's@^train  =.*@train  = testData/test.txt@' obj.data\n",
        "!sed -i 's@^valid  =.*@valid  = testData/test.txt@' obj.data\n",
        "!sed -i 's@^names = .*@names = testData/obj.names@' obj.data\n",
        "!sed -i 's@^backup = /mimer/NOBACKUP/groups/naiss2023-22-457/.*@backup = /mimer/NOBACKUP/groups/naiss2023-22-457/Experiments_results/{exp_name}/weights@' obj.data\n",
        "#!sed -i 's@classes = @classes = 3@' obj.data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPJAY639w9Yf"
      },
      "outputs": [],
      "source": [
        "!cat /content/darknet/testData/obj.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-b_M3wOw9Yf"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/terminal\n",
        "!mkdir -p /content/data/{exp_name}/{exp_name}\n",
        "!mkdir -p /content/data/{exp_name}/cfg\n",
        "!mkdir -p /content/data/{exp_name}/weights\n",
        "!cp -r /content/darknet/testData /content/data/{exp_name}\n",
        "!cp -r /content/darknet/cfg /content/data/{exp_name}\n",
        "#!mv /content/data/{exp_name}.zip /content/terminal/{exp_name}\n",
        "#!cp -r /content/terminal/{exp_name}.zip /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "%cd /content/data/\n",
        "!zip -r /content/terminal/{exp_name}.zip ./{exp_name}/*\n",
        "%cd /content/darknet/data"
      ],
      "metadata": {
        "id": "9MNMVOnfw9Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmtFVRWBw9Yg"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/terminal/{exp_name}.zip /content/gdrive/MyDrive/Colab_Notebooks/Experiments_results/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUN0ZN-JpbGm"
      },
      "outputs": [],
      "source": [
        "# change makefile to have GPU and OPENCV enabled\n",
        "%cd /content/darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAhu0j6mlfDQ"
      },
      "outputs": [],
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "!nvidia-smi\n",
        "# We need to install the correct cuDNN according to this output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr8km12dlB6s"
      },
      "source": [
        "# 7. Download pre-trained weights for the convolutional layers and put to the directory build\\darknet\\x64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-r38MSnpg9B"
      },
      "outputs": [],
      "source": [
        "# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgUQI6P6YGPX"
      },
      "source": [
        "#Download pre-trained YOLOv4 weights\n",
        "YOLOv4 has been trained already on the coco dataset which has 80 classes that it can predict. We will grab these pretrained weights so that we can run YOLOv4 on these pretrained classes and get detections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp6o-BuWpo_z"
      },
      "outputs": [],
      "source": [
        "%cd /content/darknet\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\n",
        "%cd /content/darknet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knIcCtS4bKNf"
      },
      "source": [
        "# Train Your Custom Object Detector!\n",
        "The time has finally come! You have made it to the moment of truth! You are now ready to train your custom YOLOv4 object detector on whatever crazy classes you have decided on. So run the following command. (-dont_show flag stops chart from popping up since Colab Notebook can't open images on the spot, -map flag overlays mean average precision on chart to see how accuracy of your model is, only add map flag if you have a validation dataset)\n",
        "```\n",
        "!./darknet detector train <path to obj.data> <path to custom config> yolov4.conv.137 -dont_show -map\n",
        "```\n",
        "**TIP:** This training could take several hours depending on how many iterations you chose in the .cfg file. You will want to let this run as you sleep or go to work for the day, etc. However, Colab Cloud Service kicks you off it's VMs if you are idle for too long (30-90 mins).\n",
        "\n",
        "To avoid this hold (CTRL + SHIFT + i) at the same time to open up the inspector view on your browser.\n",
        "\n",
        "Paste the following code into your console window and hit **Enter**\n",
        "```\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document\n",
        "  .querySelector('#top-toolbar > colab-connect-button')\n",
        "  .shadowRoot.querySelector('#connect')\n",
        "  .click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "```\n",
        "Looks like this, it will click the screen every 10 minutes so that you don't get kicked off for being idle! HACKS!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD8PFguJV5te"
      },
      "outputs": [],
      "source": [
        "!pwd\n",
        "%cd /content/darknet\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkbopZUbA9Zx"
      },
      "outputs": [],
      "source": [
        "!chmod +x ./darknet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb5sijXPhhzr"
      },
      "outputs": [],
      "source": [
        "!./darknet detector train data/obj.data cfg/yolo-obj.cfg yolov4.conv.137 -dont_show -map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0_z3XqKYbx0"
      },
      "outputs": [],
      "source": [
        "# train your custom detector! (uncomment %%capture below if you run into memory issues or your Colab is crashing)\n",
        "# %%capture\n",
        "!./darknet detector train /content/darknet/build/darknet/x64/data/obj.data /content/darknet/build/darknet/x64/cfg/yolo-obj.cfg /content/darknet/build/darknet/x64/yolov4.conv.137 -dont_show -map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMntdnEWYheg"
      },
      "outputs": [],
      "source": [
        "data1.add_samples(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_Po65JOVRhF"
      },
      "outputs": [],
      "source": [
        "i= 0\n",
        "for sample in data1.limit(20):\n",
        "  i += 1\n",
        "  print(i , '- ', '', '-', sample.ground_truth.detections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrFQXhDc1t-_"
      },
      "outputs": [],
      "source": [
        "print(fo.list_datasets())             #should be three dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoe23C9uoSFY"
      },
      "outputs": [],
      "source": [
        "# will show the folder size\n",
        "!du -sh /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04lGqs8zzezk"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/darknet/data/data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}